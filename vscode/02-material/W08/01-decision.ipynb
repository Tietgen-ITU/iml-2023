{
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": "py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "code",
      "id": "css_setup",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "HTML(f\"\"\"\n",
        "<style>\n",
        "@import \"https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css\";\n",
        "</style>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "UdPLPLmDWAuGsSdVG3WbF",
      "metadata": {},
      "source": [
        "# Classification and decision boundaries\n",
        "In this exercise you will be experimenting with linear classification, including visualization of decision boundaries. Noteably, the parameters of the decision boundary will not be learned with least squares but instead adjusted manually (or randomly). \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "M7APi1I7LZypSYzcHxX9R",
      "metadata": {},
      "source": [
        "import numpy as np  # numeriacal computing\n",
        "import matplotlib.pyplot as plt  # plotting core\n",
        "import seaborn as sns  # higher level plotting tools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "PLRGAMVGXQJzwCzEOoGns",
      "metadata": {},
      "source": [
        "## Linear Decision boundary\n",
        "### Generating data points\n",
        "In the following section you will be experimenting with a standard linear classifier, eg. $\\mathbf{y} = \\text{sign}(\\mathbf{w}^\\top\\mathbf{x})$, where $\\mathbf{w}$ is the model parameters.\n",
        "The cell below generates random data to be used for classification. \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "BvkLco07hQsKZVkY9lcMr",
      "metadata": {},
      "source": [
        "np.random.seed(42)  ## generate the same sequence of random points\n",
        "# Generate 2 clusters of data, by drawing from a normal distribution.\n",
        "S = np.eye(2)  ## covariance matrix, set to indenty matrix i.e. x,y independent. \n",
        "p_pos = np.random.multivariate_normal([1, 1], S, 40)\n",
        "p_neg = np.random.multivariate_normal([-1, -1], S, 40)\n",
        "## 40 points (x,y) coordinates\n",
        "p_pos.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "sJa9rnHyCu605WteittCy",
      "metadata": {},
      "source": [
        "The data of the positive and negative classes are stored in the variables `p_pos`\n",
        " and `p_neg`\n",
        ", respectively\n",
        "\n",
        "\n",
        "The next cell visualizes the two classes. \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "Bep4quosweE7-KGnxuSO9",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(p_pos[:, 0], p_pos[:, 1], \"o\", label='pos data')\n",
        "ax.plot(p_neg[:, 0], p_neg[:, 1], \"P\", label='neg data')\n",
        "plt.title(\"Data\", fontsize=24)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "usR3-oL7t6pY9bQ8MkB3J",
      "metadata": {},
      "source": [
        "In the following section, you will manually experiment with changing the model parameters of a linear decision boundary and visualize the results.\n",
        "\n",
        "---\n",
        "**Task 1 (easy): Linear decision boundaryüë©‚Äçüíª**\n",
        "1. Implement the function `linear_boundary`\n",
        " that, given an x-coordinate and the model parameters, returns the y-value according to the formula\n",
        "\n",
        "\n",
        "$y = w_1 x + w_0$\n",
        "\n",
        "2. Use the function `linear_boundary`\n",
        " to generate the points of the decision boundary with `xb`\n",
        " (following $y = w_1 x + w_0$ ). The decision boundary is specified by your choice of model parameters.\n",
        "\n",
        "3. Which choice of model parameters seems (visually) to best separate the two classes? \n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "id": "U4wljxCUUnBcmqY3NUTky",
      "metadata": {},
      "source": [
        "def linear_boundary(x, w):\n",
        "    \"\"\"\n",
        "    :param x: x values of the line.\n",
        "    :param w: List of model parameters [bias, slope] of the line.\n",
        "    \n",
        "    :return: y-values of the boundary / line .\n",
        "    \"\"\"\n",
        "    # Write solutions here\n",
        "    ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "hGeW897DU8ZQ_XHmSBnOe",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "wW5CSLtKv4Zr7RKois-3s",
      "metadata": {},
      "source": [
        "# plotting the data points and decision boundary\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(p_pos[:, 0], p_pos[:, 1], \"o\", label='pos data')\n",
        "ax.plot(p_neg[:, 0], p_neg[:, 1], \"P\", label='neg data')\n",
        "xb = np.linspace(-3, 3, 100)\n",
        "# Write solutions here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "JcHqfxNXNYtLUeZM7Nbqm",
      "metadata": {},
      "source": [
        "The prediction function predicts the class of the data points based on the y-value of the data point compared to the y-values of the decision boundary.\n",
        "\n",
        "\n",
        "---\n",
        "**Task 2 (easy): Prediction functionüë©‚Äçüíª**\n",
        "1. Implement the function `predict`\n",
        " that predicts the `class`\n",
        " of a point (whether the points belong to the `neg`\n",
        " or `pos`\n",
        " class) using the `linear_boundary`\n",
        " function.\n",
        "\n",
        "2. Implement the function `accuracy`\n",
        " that compares the _predicted class_ to the _actual class_ of given data points. The function should return the fraction of $\\frac{\\#Correct}{\\#All Points}$.\n",
        "\n",
        "3. Which parameter values provide the largest fraction of correct predictions?\n",
        "\n",
        "4. Is a linear decision boundary a good model to separate the two groups of data? \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "FdB4lGYNptMvlA3BtDwXl",
      "metadata": {},
      "source": [
        "def predict(w, p):\n",
        "    \"\"\"\n",
        "    :param w: parameters of your decision function.\n",
        "    :param p: The data points to predict.\n",
        "    \n",
        "    :return: 0 if `neg` class / 1 if `pos` class.\n",
        "    \"\"\"\n",
        "    # Write solutions here\n",
        "    ...\n",
        "\n",
        "\n",
        "def accuracy(predictions,targets):\n",
        "    \"\"\"\n",
        "    :param predictions: 1D-array of predicted classes for the data.\n",
        "    :param targets: 1D-array of actual classes for the data.\n",
        "     \n",
        "    :return: fraction of correctly predicted points (num_correct/num_points).\n",
        "    \"\"\"\n",
        "    # Write solutions here\n",
        "    ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "B6akbYuI7gAwXuDYY3Fey",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "l64TfHUVbEynqaMkKg1Gz",
      "metadata": {},
      "source": [
        "# print accuracy \n",
        "#\n",
        "# write reflection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "TjxX4Af_Iez87JAiFeK7s",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "**Task 3 (medium): Random Search Optimizationüë©‚Äçüíª**\n",
        "The goal of this exercise is to implement the function `random_optimization`\n",
        " that utilizes randomly chosen model parameters to search for the linear decision boundary in the binary dataset.\n",
        "1. Implement the function `random_optimization`\n",
        ":\n",
        "    - In the function template, initialize best_params (remember it is a list) and best_score with the value zero.\n",
        "    - Create the targets for the data (1s for `p_pos`\n",
        " and 0s for `p_neg`\n",
        ")\n",
        "    - Run `num_iterations`\n",
        " iterations and use `np.random.randn()`\n",
        " to generate new random parameters during each iteration.\n",
        "    - Predict the classes of the data using the function `predict`\n",
        ".\n",
        "    - Evaluate the performance of the random parameters with the `accuracy`\n",
        " function.\n",
        "    - Compare the accuracy achievied with the current parameters to the best parameters and update the best choice accordingly.\n",
        "    - Return the best parameters and their accuracy.\n",
        "\n",
        "\n",
        "2. Find the best parameters, by executing `random_optimization`\n",
        ". Pass the necessary `decision_function`\n",
        " and `accuracy`\n",
        ", along with the dataset and set `num_iterations`\n",
        " to 50.\n",
        "\n",
        "3. Visualize Decision Boundary:\n",
        "    - Set up a visualization using Matplotlib, plotting your 2-class dataset points.\n",
        "    - Plot the optimal decision boundary based on the parameters found.\n",
        "\n",
        "\n",
        "4. Analysis:\n",
        "    - Based on the results, determine if a linear decision boundary is suitable for your dataset.\n",
        "    - Discuss the efficiency of random search in optimizing the decision boundary and its limitations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "id": "7p6bs0cXOc_bp5jXpsRkG",
      "metadata": {},
      "source": [
        "def random_optimization(data, num_iterations=1000):\n",
        "    \"\"\"\n",
        "    Performs a random search optimization to find the best decision boundary for a 2-class dataset.\n",
        "    :param data: The dataset, structured as [positive examples, negative examples].\n",
        "    :param num_iterations: Number of random configurations to test.\n",
        "\n",
        "    :return: The best parameters found and their score.\n",
        "    \"\"\"\n",
        "    # Write solutions here\n",
        "    ...\n",
        "\n",
        "\n",
        "# best_params, best_score = random_optimization(linear_boundary, fraction_correct,[p1,p2], num_iterations=50)\n",
        "# plot the results ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "g-F2eGMoPMuDU4mybOYd2",
      "metadata": {},
      "source": [
        "## Non-linear decision boundary\n",
        "The following section experiments with a different dataset (see visualization in the cell below), where a straight line cannot seperate the different classes in the data. \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "H3oL3D0PL81BWjlxw0zEe",
      "metadata": {},
      "source": [
        "### Data generation\n",
        "q1 = np.random.multivariate_normal([0, 0], [[.5, 0], [0, .5]], 400)\n",
        "\n",
        "t = np.linspace(0, 2 * np.pi, 400)  ##  \n",
        "q2 = np.array([(3 + q1[:, 0]) * np.sin(t), (3 + q1[:, 1]) * np.cos(t)]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "sNFlSsFpBJO68gfrkmwNB",
      "metadata": {},
      "source": [
        "The data of the two classes (`class 1`\n",
        " and `class 2`\n",
        ") are stored in the variables `q1`\n",
        " and `q2`\n",
        ", respectively.\n",
        "\n",
        "\n",
        "The following cell visualize the dataset of the two classes. `class 1`\n",
        " is labelled with 0s and `class 2`\n",
        " with 1s.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "8QQWSFFthPjhNyKBSMyo0",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(q2[:, 0], q2[:, 1], \"o\", label='class 2')\n",
        "ax.plot(q1[:, 0], q1[:, 1], \"o\", label='class 1')\n",
        "\n",
        "plt.title(\"Non-linear data\", fontsize=24)\n",
        "ax.axis('equal')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "rY50J6FLToYAHOrqODdLN",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "**Task 4 (easy): Non-linear dataüë©‚Äçüíª**\n",
        "1. What is the best accuracy you can achieve if you attempt to predict the class of the data with a straight line? (Use your implementation from [Task 1](#linear) )\n",
        "\n",
        "2. Instead of a straight line, use the parametric equation of a circle ([described in detail here](https://mathopenref.com/coordparamcircle.html)\n",
        "):\n",
        "\n",
        "$$ \n",
        "    x = r\\sin(t)\\\\\n",
        "    y = r\\cos(t)\n",
        "    $$\n",
        "to create the function `circle_boundary`\n",
        " that, given `t`\n",
        " (array of angles) and the radius `r`\n",
        " as input, returns the $x$- and $y$-coordinates of the circle.\n",
        "\n",
        "**Tip**\n",
        "Use the already provided `t`\n",
        " to plot a circular boundary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "id": "fnxZHBQBv_lPq_V35W5Kr",
      "metadata": {},
      "source": [
        "t = np.linspace(0, 2 * np.pi, 400)  ### create 400 points in the range 0 ->2*pi (angles in radian units) \n",
        "\n",
        "\n",
        "def circle_boundary(t, radius):\n",
        "    \"\"\"\n",
        "    :param t: angle data points of the circle. \n",
        "    :param radius: radius of the circle\n",
        "    :return: (x-values,y-values) of the circle points .\n",
        "    \"\"\"\n",
        "    # Write solutions here\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(q2[:, 0], q2[:, 1], \"o\", label='class 2')\n",
        "ax.plot(q1[:, 0], q1[:, 1], \"P\", label='class 1')\n",
        "\n",
        "# plot the circle here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "gIncpxpmnQBciI2mwaJy9",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "**Task 5 (easy): Predict non-linear dataüë©‚Äçüíªüí°**\n",
        "1. Which choice of radius seems (visually) to best separate the two classes?\n",
        "2. Could the decision boundary from above be learned by a linear model? \n",
        "\n",
        "\n",
        "**Tip**\n",
        "A Linear model in machine learning refers to being linear in the parameters. \n",
        "\n",
        "3. Modify the `predict`\n",
        " function from [Task 2](#predict) to return the estimated class of the datapoint using a circlular decision boundary (simply the radius).\n",
        "4. Use the function `accuracy`\n",
        " to get the fraction of correctly predicted data points.\n",
        "\n",
        "\n",
        "**Tip**\n",
        "Separating the classes can be done if your predict based on whether $x^2+y^2$ is $>r^2$ or $<r^2$\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "id": "FF9WjGhRXVoymGFt1hH3Y",
      "metadata": {},
      "source": [
        "def predict_circle(radius, data):\n",
        "    \"\"\"\n",
        "    :param radius: radius of the circular decision boudary.\n",
        "    :param data: List containing the two classes of data points.\n",
        "    \n",
        "    :return: fraction of correctly predicted points (num_correct/num_points).\n",
        "    \"\"\"\n",
        "    # Write your implementation here\n",
        "\n",
        "# Write your implementation here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "RQKb-9VcE7-oF6YG13e-I",
      "metadata": {},
      "source": [
        ""
      ]
    }
  ]
}
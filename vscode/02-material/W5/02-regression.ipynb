{"metadata":{"kernelspec":{"language":"python3","display_name":"Python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":"py","mimetype":"text/x-python","name":"python"}},"nbformat":4,"nbformat_minor":5,"cells":[{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":{"outputs_hidden":null,"source_hidden":true},"format":null,"name":null,"tags":null},"source":["import requests\n","from IPython.core.display import HTML\n","HTML(f\"\"\"\n","<style>\n","@import \"https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css\";\n","</style>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["# Generalising linear regression\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["import numpy as np\n","from scipy import stats\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["In this exercise you will generalise regression to $N$-th order polynomials and use it to predict the price of a house (in Canadian dollars) based on its lot size (in square feet).\n","Suppose you want to buy a house in the City of Windsor, Canada. You contact a real-estate salesperson to get information about current house prices and receive details on 546 properties sold in Windsor in the last two years. You would like to figure out what the expected cost of a house might be given only the lot size of the house you want to buy. Fortunately, his dataset has only one independent variable (i.e. `lotsize`\n",", the lot size of a property) and one dependent variable (i.e. `price`\n",", the sale price of a house). You will train the dataset using polynomial regression to predict the house prices.\n","A polynomial _model_ of order $N$ is defined by:\n","\n","$$\n","f_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\dots + \\theta_N x^N,\n","$$\n","\n","in which, the coefficients $\\theta_i$ are the parameters of the model. Notice how the function is linear in the parameters, i.e. if $x$ is fixed, the function is linear. To estimate the parameters $\\theta_i$, you can therefore set up a linear equation and solve for $\\theta$:\n","\n","$$\n","\\begin{bmatrix}\n","    1 & x_1 & x_1^2 & x_1^3 & \\dots & x_1^N \\\\\n","    1 & x_2 & x_2^2 & x_2^3 & \\dots & x_2^N \\\\\n","    1 & x_3 & x_3^2 & x_3^3 & \\dots & x_3^N \\\\\n","    \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","    1 & x_m & x_m^2 & x_m^3 & \\dots & x_m^N\n","\\end{bmatrix}\n","\\times\n","\\begin{bmatrix}\n","    \\theta_0 \\\\\n","    \\theta_1 \\\\\n","    \\theta_2 \\\\\n","    \\theta_3 \\\\\n","    \\vdots \\\\\n","    \\theta_N\n","\\end{bmatrix}\n","=\n","\\begin{bmatrix}\n","    y_1 \\\\\n","    y_2 \\\\\n","    y_3 \\\\\n","    \\vdots \\\\\n","    y_m\n","\\end{bmatrix},\n","$$\n","\n","or more compactly: $A \\theta = y$. \n","The _cost function_ $\\ell(\\hat{y}_i, y_i)$ for linear regression is the mean squared error between the known outputs $y_i$ and the predicted outputs $\\hat{y}=f_{\\theta}(x)$ of the model:\n","\n","$$\n","\\ell(\\hat{y}_i, y_i) = (\\hat{y}_i-y_{i})^2\n","$$\n","\n","This cost function is simply the squarred error of each point. We know from the projection method that least squares minimises the sum of squares. In other words, the parameters $\\theta$ can be decided by solving the following optimisation problem:\n","\n","$$\n","\\theta = \\underset{\\theta}{\\operatorname{argmin}} \\frac{1}{m}\\sum_{i=1}^{m} \\ell(\\hat{y}_i, y_i)\n","$$\n","\n","Just to summarize, we have our _model_ $f_\\theta(x)$ which is a polynomial function in $x$. We then want to find parameters $\\theta$ that minimizes the squared distance (the $\\frac{1}{m}$ is just for scaling). We know from linear algebra that projecting the vector $(f(x_1), \\dots, f(x_m)$ onto the column space of the design matrix defined by $A$ is equivalent to solving that optimisation problem.\n","## Data exploration\n","Load the dataset described above:\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["filename = \"./data/simple_windsor.csv\"\n","names = [\"lotsize\", \"price\"]\n","dataset = np.loadtxt(filename, delimiter=',', dtype=np.int32)\n","\n","X_full, y_full = dataset.T\n","np.random.randn(2, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["Let us visualise the data:\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["plt.scatter(X_full, y_full)\n","plt.xlabel('Lot size')\n","plt.ylabel('House price');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["This visualisation already tells us a lot about the usefulness of the data. Try to answer the following questions to the best of your abilities:\n","\n","---\n","**Task 1 (easy): Questions**\n","Notice the large spread in house prices for relatively similar lot sizes. \n","1. List at least three reasons for the house price variability given the lot size.\n","\n","\n","---\n","### Splitting into train and test data\n","We use a helper function from the _Scikit Learn_ library to split the dataset into $80\\%$ training data and $20\\%$ test data:\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["## Generalising regression\n","The steps for linear regression are:\n","1. Define a model, e.g. linear or polynomial, and identity knowns and uknowns.\n","2. Generate a design matrix $A$ for the input dataset (see the ´get_design_matrix´ function below).\n","3. Estimate the model parameters using least squares ([Task 2](#estimate)).\n","\n","The following exercises will guide you through this process.\n","We provide the function below for creating design matrices for polynomials of arbitrary order:\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def get_design_matrix(x, order=1):\n","    \"\"\"\n","    Get the coefficients of polynomial in a least square sense of order N.\n","    \n","    :param x: Must be numpy array of size (N).\n","    :order n: Order of Polynomial.\n","    \"\"\"\n","    \n","    if order < 1 or x.ndim != 1:\n","        return x\n","\n","    count = x.shape[0]\n","    matrix = np.ones((count, order + 1), np.float64)\n","\n","    for i in range(1, order+1):\n","        matrix[:, i] = np.power(x, i)\n","\n","    return matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 2 (easy): Estimate parameters**\n","1. Implement the function `estimate(X, y, order)`\n"," below. The function should use `np.linalg.lstsq()`\n"," to estimate the model parameters. Use `get_design_matrix(X, order)`\n"," to generate an appropriate design matrix.\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def estimate(X, y, order):\n","    \"\"\"\n","    :param X: Input vector.\n","    :param y: Training data values.\n","    :param order: Order of the model to estimate.\n","    \n","    :return: Parameters of model.\n","    \"\"\"\n","    ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 3 (easy): Implement linear model**\n","1. Use the learned model to predict house prices given an input vector $X$ of lot sizes. Implement the prediction function `predict(X, params)`\n"," in the cell below. \n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def predict(X, params):\n","    \"\"\"\n","    :param X: Input vector.\n","    :param params: Estimated parameters.\n","    \n","    :return: Predicted y-values.\n","    \"\"\"\n","    ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 4 (easy): Prediction**\n","In this task you will combine the functions above to learn the model parameters for a polynomial model and use it for predictions of house prices. Implement the following steps in the code cell below.\n","1. Estimate parameters from `X_train`\n"," and `y_train`\n",". \n","2. Then calculate the predicted `y`\n","-values for the provided lot-sizes in the variable `values`\n"," in the cell below. \n","3. Plot the predicted house prices as a line-plot.\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["values = np.linspace(X_full.min(), X_full.max(), 50)\n","\n","# (A) Estimate parameters\n","\n","# (B) Evaluate model\n","\n","plt.scatter(X_train, y_train)\n","\n","# (C) Plot predicted values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 5 (easy)**\n","In this task you will experiment with the order of the polynomial model.\n","1. Increase the order of the polynomial in your implementation above and evaluate the results.\n","a. A $3.$-order polynomial.\n","b. A $4.$-order polynomial.\n","c. A $7.$-order polynomial.\n","\n","You should see the predictions starting to deviate drastically for the $7.$-order polynomial. \n","1. Try to explain why this happens? _Hint: It has to do with the behavior of floating point numbers at extreme values._\n","\n","\n","---\n","The above problem can be solved by normalizing the input vectors. Normalization scales and translates (transforms) a series of input values to the interval $(0, 1)$ by using the minimum and maximum values of the inputs. \n","The cell below provides helper functions for normalizing and unnormalising (the inverse transformation) input vectors:\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def normalized(X):\n","    n = (X - np.min(X_full))/np.max(X_full)\n","    return n\n","\n","def unnormalized(X):\n","    return X*np.max(X_full) + np.min(X_full)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 6 (medium): Higher order polynomials with normalization**\n","In this task you will need to modify the code in [Task 4](#learn) using the helper functions above to normalize the inputs $X_{train}$ and re-train the model.\n","1. Normalize the inputs in the variable `X_{train}`\n",". \n","2. Re-train the model parameters using the normalized inputs and plot the results. Use $3.$, $4.$, and $7.$ order polynomials as done in [Task 4](#learn).\n","3. How much did the results improve for the different model orders? Explain why normalization achieves better performance.\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["values = np.linspace(X_full.min(), X_full.max(), 50)\n","\n","# Estimate parameters and predict y-values\n","\n","plt.scatter(X_train, y_train, c=\"g\")\n","\n","# Plot predicted values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["---\n","## Evaluation\n","We now want to evaluate the model using the test data. You will calculate the _root mean squarred error_ for various orders of polynomials and use the error to decide which order has the best tradeoff between bias and variance (underfitting/overfitting).\n","The _root mean squared error_ is simply the square root of the _mean squared error_: \n","\n","$$\n"," \\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(h_{\\theta}(x_{i})-y_{i})^2}\n","$$\n","\n","We use it because it represents the average error in the same units as the data, i.e. house prices in our case.\n","\n","---\n","**Task 7 (easy): Error calculation**\n","Implement the _root mean squared error_ in the `rmse`\n"," function below.\n","1. Normalize the `X`\n"," values using the `normalized`\n"," function\n","2. Predict the prices using the normalized `X`\n"," values and model parameters `theta`\n","\n","3. Calculate and return the _root mean squared error_ of the predicted values\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def rmse(theta, X, y):\n","    ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 8 (easy): Model evaluation**\n","The function `evaluate_models`\n"," in the cell below should calculate the _root mean squared error_ for models with polynomial orders from 1 to 20. You have to finish the implementation, starting at the `# Add code here`\n"," comment. Do the following:\n","1. Estimate the model parameters using the `estimate`\n"," function.\n","2. Calculate the _root mean squared error_ of the train and test sets respectively.\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["def evaluate_models():\n","    losses_train = []\n","    losses_test = []\n","    for order in range(1, 20):\n","        # Add code here\n","        # first, estimate parameters\n","        rmse_train = ...\n","        rmse_test = ...\n","        losses_train.append(rmse_train)\n","        losses_test.append(rmse_test)\n","    return losses_train, losses_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 9 (easy): Plotting results**\n","1. Plot the training and test losses in the cell below. \n","2. Are the results what you expected? Explain why the two loss values evolve differently as the order of the polynomial increases.\n","3. Relate the results to the dilemma of underfitting and overfitting.\n","\n","\n","---\n",""]},{"cell_type":"code","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["# Write your solution here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":null,"autoscroll":null,"deletable":null,"jupyter":null,"format":null,"name":null,"tags":null},"source":["\n","---\n","**Task 10 (medium): Reflection**\n","1. Is it possible to improve the test loss to an arbitrarily low value if you could use a different model?\n","2. Explain why this is or is not possible.\n","\n","\n","---\n",""]}]}